{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c4da94",
   "metadata": {},
   "source": [
    "# YOLO11 Two-Stage Training ‚Äì HT_Vision Dataset (Robust to Interruptions)\n",
    "\n",
    "This notebook implements a **robust two-stage YOLO11 training pipeline** for the `HT_Vision_Dataset`.\n",
    "\n",
    "Pipeline overview:\n",
    "\n",
    "1. **Stage 1** ‚Äì Train YOLO11 at 640√ó640 with tuned hyperparameters.\n",
    "2. **Stage 1 Evaluation** ‚Äì Evaluate on **val** and **test** splits, and inspect the **best** and **worst** detections (IoU with ground truth).\n",
    "3. **Stage 2** ‚Äì Fine-tune starting from Stage 1 best weights at 960√ó960.\n",
    "4. **Stage 2 Evaluation** ‚Äì Again evaluate on **val** and **test**, with best/worst detection inspection.\n",
    "5. **Compare Stage 1 vs Stage 2 metrics**.\n",
    "6. **Inference** ‚Äì Run inference with Stage 1 and Stage 2 on a **custom image**:\n",
    "\n",
    "```text\n",
    "/mnt/Data1/mpiccolo/HT_Vision/inference_pinksalmon.png\n",
    "```\n",
    "\n",
    "7. Prepare a cell for **unseen dataset evaluation** (path to be defined later).\n",
    "\n",
    "Robustness design:\n",
    "\n",
    "- Training does **not** skip just because `best.pt` exists.\n",
    "- It checks how many epochs are recorded in `results.csv`.\n",
    "- If epochs done `< target`, it continues training (starting from `last.pt` if available).\n",
    "- If epochs done `>= target` and `best.pt` exists, training is skipped as *complete*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627c7726",
   "metadata": {},
   "source": [
    "## 1. Environment setup\n",
    "\n",
    "Install and import the required libraries.\n",
    "\n",
    "> If `ultralytics` is already installed in your environment, you can skip the `pip install` line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6131ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version : 2.8.0+cu128\n",
      "CUDA available  : True\n",
      "CUDA device     : NVIDIA GeForce RTX 5070 Ti\n"
     ]
    }
   ],
   "source": [
    "# If ultralytics is not installed, uncomment the next line\n",
    "# !pip install ultralytics --upgrade\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(f\"PyTorch version : {torch.__version__}\")\n",
    "print(f\"CUDA available  : {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device     : {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deab53a",
   "metadata": {},
   "source": [
    "## 2. Global configuration\n",
    "\n",
    "Define dataset paths, training results folder, model weights, and common settings.\n",
    "\n",
    "The `val` split specified in `data.yaml` will be used automatically by YOLO for validation, early stopping, and best-model selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5313440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_YAML     : /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/data.yaml\n",
      "TRAINING_ROOT : /mnt/Data1/mpiccolo/HT_Vision/Training_Results\n",
      "Stage1 root   : /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1\n",
      "Stage2 root   : /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage2\n",
      "Stage3 root   : /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3\n",
      "Using model   : yolo11m.pt\n",
      "Device        : 0\n",
      "Inference img : /mnt/Data1/mpiccolo/HT_Vision/inference_pinksalmon.png\n"
     ]
    }
   ],
   "source": [
    "# Base dataset directory (matches data.yaml path)\n",
    "ROOT_DIR = Path(\"/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset\")\n",
    "\n",
    "# Path to data.yaml\n",
    "DATA_YAML = ROOT_DIR / \"data.yaml\"\n",
    "\n",
    "# Root folder for structured training results (Stage1, Stage2)\n",
    "TRAINING_ROOT = Path(\"/mnt/Data1/mpiccolo/HT_Vision/Training_Results\")\n",
    "TRAINING_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Stage-specific root folders\n",
    "STAGE1_ROOT = TRAINING_ROOT / \"Stage1\"\n",
    "STAGE2_ROOT = TRAINING_ROOT / \"Stage2\"\n",
    "STAGE3_ROOT = TRAINING_ROOT / \"Stage3\"\n",
    "STAGE1_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "STAGE2_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "STAGE3_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# YOLO model checkpoint to start from (Stage 1)\n",
    "YOLO11_WEIGHTS = \"yolo11m.pt\"\n",
    "\n",
    "# Common settings\n",
    "IMG_SIZE_STAGE1 = 640\n",
    "IMG_SIZE_STAGE2 = 960\n",
    "IMG_SIZE_STAGE3 = 1024\n",
    "\n",
    "DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "EXPERIMENT_BASE_NAME = \"yolo11_ht_vision_fish\"\n",
    "\n",
    "# Inference image\n",
    "INFERENCE_IMAGE = \"/mnt/Data1/mpiccolo/HT_Vision/inference_pinksalmon.png\"\n",
    "\n",
    "print(f\"DATA_YAML     : {DATA_YAML}\")\n",
    "print(f\"TRAINING_ROOT : {TRAINING_ROOT}\")\n",
    "print(f\"Stage1 root   : {STAGE1_ROOT}\")\n",
    "print(f\"Stage2 root   : {STAGE2_ROOT}\")\n",
    "print(f\"Stage3 root   : {STAGE3_ROOT}\")\n",
    "print(f\"Using model   : {YOLO11_WEIGHTS}\")\n",
    "print(f\"Device        : {DEVICE}\")\n",
    "print(f\"Inference img : {INFERENCE_IMAGE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df121fb0",
   "metadata": {},
   "source": [
    "## 3. Reproducibility\n",
    "\n",
    "We set a fixed random seed to make experiments as reproducible as possible (Python `random`, NumPy, and PyTorch CPU/CUDA).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29333a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "print(f\"Seed set to {SEED}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804856e2",
   "metadata": {},
   "source": [
    "## 4. Dataset sanity checks\n",
    "\n",
    "Verify that:\n",
    "\n",
    "- `data.yaml` exists.\n",
    "- `images/train`, `images/val`, and `images/test` exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23030748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dataset directories...\n",
      "  /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/train -> OK\n",
      "  /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/val -> OK\n",
      "  /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/test -> OK\n"
     ]
    }
   ],
   "source": [
    "assert DATA_YAML.is_file(), f\"data.yaml not found at: {DATA_YAML}\"\n",
    "\n",
    "train_dir = ROOT_DIR / \"images\" / \"train\"\n",
    "val_dir   = ROOT_DIR / \"images\" / \"val\"\n",
    "test_dir  = ROOT_DIR / \"images\" / \"test\"\n",
    "\n",
    "print(\"Checking dataset directories...\")\n",
    "for p in [train_dir, val_dir, test_dir]:\n",
    "    print(f\"  {p} -> {'OK' if p.is_dir() else 'MISSING'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d8c63",
   "metadata": {},
   "source": [
    "## 5. Helper functions\n",
    "\n",
    "We define helpers to:\n",
    "\n",
    "- Run evaluation and save metrics to JSON.\n",
    "- Export metrics to CSV.\n",
    "- Analyze **best** and **worst** detections on the test split by IoU with ground truth bounding boxes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f5499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save(weights_path: Path,\n",
    "                      data_yaml: Path,\n",
    "                      split: str,\n",
    "                      imgsz: int,\n",
    "                      project: Path,\n",
    "                      name: str,\n",
    "                      seed: int,\n",
    "                      out_json: Path):\n",
    "    # Run YOLO .val, save metrics to JSON, and return (metrics_dict, results_obj).\n",
    "    model_eval = YOLO(str(weights_path))\n",
    "    kwargs = dict(\n",
    "        data=str(data_yaml),\n",
    "        imgsz=imgsz,\n",
    "        seed=seed,\n",
    "        project=str(project),\n",
    "        name=name,\n",
    "        exist_ok=True,\n",
    "        plots=True,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    if split in (\"train\", \"val\", \"test\"):\n",
    "        kwargs[\"split\"] = split\n",
    "\n",
    "    results_obj = model_eval.val(**kwargs)\n",
    "    try:\n",
    "        metrics = getattr(results_obj, \"results_dict\", results_obj) if results_obj is not None else {}\n",
    "    except Exception:\n",
    "        metrics = {}\n",
    "\n",
    "    out_json.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_json.open(\"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    return metrics, results_obj\n",
    "\n",
    "\n",
    "def export_metrics_csv(metrics_val: dict, metrics_test: dict, csv_path: Path):\n",
    "    # Save validation and test metrics to a CSV file.\n",
    "    fields = sorted(set(metrics_val.keys()) | set(metrics_test.keys()))\n",
    "    csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with csv_path.open(\"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"metric\", \"val\", \"test\"])\n",
    "        for k in fields:\n",
    "            writer.writerow([k, metrics_val.get(k, \"\"), metrics_test.get(k, \"\")])\n",
    "    print(\"Metrics CSV saved to\", csv_path)\n",
    "\n",
    "\n",
    "def box_iou_xyxy(box1, box2):\n",
    "    # Compute IoU between two boxes in XYXY format (x1, y1, x2, y2).\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    inter_w = max(0.0, x2 - x1)\n",
    "    inter_h = max(0.0, y2 - y1)\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    area1 = max(0.0, box1[2] - box1[0]) * max(0.0, box1[3] - box1[1])\n",
    "    area2 = max(0.0, box2[2] - box2[0]) * max(0.0, box2[3] - box2[1])\n",
    "    union = area1 + area2 - inter + 1e-6\n",
    "\n",
    "    return inter / union\n",
    "\n",
    "\n",
    "def load_gt_boxes_yolo_format(image_path: str, split: str, orig_shape):\n",
    "    # Load ground truth boxes from labels/<split> in YOLO format and convert to XYXY pixels.\n",
    "    h, w = orig_shape  # (height, width)\n",
    "    label_dir = ROOT_DIR / \"labels\" / split\n",
    "    label_path = label_dir / (Path(image_path).stem + \".txt\")\n",
    "    if not label_path.is_file():\n",
    "        return []\n",
    "\n",
    "    gt_boxes = []\n",
    "    with label_path.open(\"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            cls, cx, cy, bw, bh = map(float, parts[:5])\n",
    "            x_center = cx * w\n",
    "            y_center = cy * h\n",
    "            box_w = bw * w\n",
    "            box_h = bh * h\n",
    "            x1 = x_center - box_w / 2.0\n",
    "            y1 = y_center - box_h / 2.0\n",
    "            x2 = x_center + box_w / 2.0\n",
    "            y2 = y_center + box_h / 2.0\n",
    "            gt_boxes.append([x1, y1, x2, y2])\n",
    "    return gt_boxes\n",
    "\n",
    "\n",
    "def analyze_best_worst_detections(results_obj, split: str = \"test\", top_k: int = 2, min_iou: float = 0.0):\n",
    "    # From a YOLO .val results object, compute IoU between predictions and GT and\n",
    "    # print the best and worst detections (by IoU).\n",
    "    if results_obj is None:\n",
    "        print(\"No results object provided for analysis.\")\n",
    "        return\n",
    "\n",
    "    img_results = getattr(results_obj, \"results\", None)\n",
    "    if img_results is None:\n",
    "        print(\"The results object does not contain per-image results.\")\n",
    "        return\n",
    "\n",
    "    pairs = []  # list of dicts with keys: iou, image, pred_box, gt_box, score\n",
    "    for r in img_results:\n",
    "        image_path = r.path\n",
    "        orig_shape = r.orig_shape  # (h, w)\n",
    "        gt_boxes = load_gt_boxes_yolo_format(image_path, split=split, orig_shape=orig_shape)\n",
    "        if not gt_boxes:\n",
    "            continue\n",
    "\n",
    "        if r.boxes is None or r.boxes.xyxy is None:\n",
    "            continue\n",
    "\n",
    "        pred_boxes = r.boxes.xyxy.cpu().numpy()\n",
    "        pred_scores = r.boxes.conf.cpu().numpy()\n",
    "\n",
    "        for i, pb in enumerate(pred_boxes):\n",
    "            best_iou = 0.0\n",
    "            best_gt = None\n",
    "            for gb in gt_boxes:\n",
    "                iou = box_iou_xyxy(pb, gb)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt = gb\n",
    "            if best_gt is not None and best_iou >= min_iou:\n",
    "                score = float(pred_scores[i]) if i < len(pred_scores) else None\n",
    "                pairs.append(\n",
    "                    {\n",
    "                        \"iou\": float(best_iou),\n",
    "                        \"image\": image_path,\n",
    "                        \"pred_box\": pb.tolist(),\n",
    "                        \"gt_box\": best_gt,\n",
    "                        \"score\": score,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    if not pairs:\n",
    "        print(\"No prediction‚ÄìGT pairs found for analysis.\")\n",
    "        return\n",
    "\n",
    "    pairs_sorted = sorted(pairs, key=lambda x: x[\"iou\"])\n",
    "    worst = pairs_sorted[:top_k]\n",
    "    best = pairs_sorted[-top_k:] if len(pairs_sorted) >= top_k else pairs_sorted\n",
    "\n",
    "    print(f\"\\n=== Best {len(best)} detections (highest IoU) ===\")\n",
    "    for p in reversed(best):\n",
    "        print(f\"Image: {p['image']}\")\n",
    "        if p[\"score\"] is not None:\n",
    "            print(f\"  IoU : {p['iou']:.4f}, score: {p['score']:.4f}\")\n",
    "        else:\n",
    "            print(f\"  IoU : {p['iou']:.4f}\")\n",
    "        print(f\"  Pred box: {p['pred_box']}\")\n",
    "        print(f\"  GT box  : {p['gt_box']}\\n\")\n",
    "\n",
    "    print(f\"\\n=== Worst {len(worst)} detections (lowest IoU) ===\")\n",
    "    for p in worst:\n",
    "        print(f\"Image: {p['image']}\")\n",
    "        if p[\"score\"] is not None:\n",
    "            print(f\"  IoU : {p['iou']:.4f}, score: {p['score']:.4f}\")\n",
    "        else:\n",
    "            print(f\"  IoU : {p['iou']:.4f}\")\n",
    "        print(f\"  Pred box: {p['pred_box']}\")\n",
    "        print(f\"  GT box  : {p['gt_box']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d3f2d7",
   "metadata": {},
   "source": [
    "## 6. Stage 1 ‚Äì Training at 640√ó640 (robust with epoch check)\n",
    "\n",
    "We now train Stage 1 using your **final consolidated hyperparameters**:\n",
    "\n",
    "```python\n",
    "BEST_OPTIMIZER = \"SGD\"\n",
    "BEST_DROPOUT = 0.1\n",
    "BEST_LR0 = 0.00164\n",
    "BEST_BOX_WEIGHT = 5.0\n",
    "BEST_CLS_WEIGHT = 0.4\n",
    "BEST_OBJ_WEIGHT = 1.0   # kobj\n",
    "\n",
    "# Augmentation\n",
    "BEST_MOSAIC = 0.9129\n",
    "BEST_MIXUP = 0.4553\n",
    "BEST_FLIPUD = 0.07835\n",
    "BEST_FLIPLR = 0.5\n",
    "BEST_HSV_H = 0.0083\n",
    "BEST_HSV_S = 0.02738\n",
    "BEST_HSV_V = 0.33474\n",
    "\n",
    "# Schedule\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 300\n",
    "WARMUP_EPOCHS = 3\n",
    "WARMUP_MOMENTUM = 0.8\n",
    "```\n",
    "\n",
    "Robustness:\n",
    "\n",
    "- We check how many epochs are recorded in `results.csv`.\n",
    "- If `epochs_done < EPOCHS_STAGE1`, we continue training (from `last.pt` if available).\n",
    "- If `epochs_done >= EPOCHS_STAGE1` and `best.pt` exists, we skip training as *complete*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d19174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 experiment name: yolo11_ht_vision_fish_stage1_640\n"
     ]
    }
   ],
   "source": [
    "# === Stage 1 Hyperparameters ===\n",
    "BEST_OPTIMIZER = \"SGD\"\n",
    "BEST_DROPOUT = 0.1\n",
    "BEST_LR0 = 0.00164\n",
    "BEST_BOX_WEIGHT = 5.0\n",
    "BEST_CLS_WEIGHT = 0.4\n",
    "BEST_OBJ_WEIGHT = 1.0   # kobj\n",
    "\n",
    "# Augmentation\n",
    "BEST_MOSAIC = 0.9129\n",
    "BEST_MIXUP = 0.4553\n",
    "BEST_FLIPUD = 0.07835\n",
    "BEST_FLIPLR = 0.5\n",
    "BEST_HSV_H = 0.0083\n",
    "BEST_HSV_S = 0.02738\n",
    "BEST_HSV_V = 0.33474\n",
    "\n",
    "# Schedule\n",
    "BATCH_SIZE_STAGE1 = 16\n",
    "EPOCHS_STAGE1 = 300\n",
    "WARMUP_EPOCHS = 3\n",
    "WARMUP_MOMENTUM = 0.8\n",
    "\n",
    "# Other training parameters\n",
    "LRS_STAGE1_FINAL_MULT = 0.1\n",
    "MOMENTUM_STAGE1 = 0.9\n",
    "WEIGHT_DECAY_STAGE1 = 0.0005\n",
    "DFL_STAGE1 = 2.0\n",
    "PATIENCE_STAGE1 = 50\n",
    "\n",
    "STAGE1_NAME = f\"{EXPERIMENT_BASE_NAME}_stage1_640\"\n",
    "print(\"Stage 1 experiment name:\", STAGE1_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07854bfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 experiment dir: /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640\n",
      "Existing Stage 1 best.pt: True\n",
      "Existing Stage 1 last.pt: True\n",
      "Existing Stage 1 results.csv: True\n",
      "Stage 1 epochs recorded in results.csv: 201 / 300\n",
      "\n",
      "--- Resuming Stage 1 from last.pt with true YOLO resume ---\n",
      "New https://pypi.org/project/ultralytics/8.3.228 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.197 üöÄ Python-3.9.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 15840MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=5.0, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.4, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=2.0, dnn=False, dropout=0.1, dynamic=False, embed=None, epochs=300, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.07835, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0083, hsv_s=0.02738, hsv_v=0.33474, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00164, lrf=0.1, mask_ratio=4, max_det=1000, mixup=0.4553, mode=train, model=/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/weights/last.pt, momentum=0.9, mosaic=0.9129, multi_scale=False, name=yolo11_ht_vision_fish_stage1_640, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1, rect=False, resume=/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/weights/last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640, save_frames=False, save_json=False, save_period=25, save_txt=False, scale=0.5, seed=42, shear=2.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 23        [16, 19, 22]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLO11m summary: 231 layers, 20,053,779 parameters, 20,053,763 gradients, 68.2 GFLOPs\n",
      "\n",
      "Transferred 649/649 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2941.7¬±2390.8 MB/s, size: 55.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/labels/train.cache... 20130 images, 1590 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 20130/20130 47.5Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/train/fishclef_00030.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/train/fishclef_04732.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/train/fishclef_05932.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/train/fishclef_07144.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/train/fishclef_10671.jpg: 1 duplicate labels removed\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (40.5GB Disk): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 20130/20130 2.3Kit/s 8.8s<0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2564.1¬±2486.3 MB/s, size: 92.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/labels/val.cache... 5752 images, 455 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5752/5752 9.3Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/val/fishclef_05829.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/val/fishclef_05830.jpg: 2 duplicate labels removed\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (11.6GB Disk): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5752/5752 1.8Kit/s 3.2s0.0s\n",
      "Plotting labels to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00164, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n",
      "Resuming training /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/weights/last.pt from epoch 202 to 300 total epochs\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    202/300      8.03G     0.7119     0.5125      1.434          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.0it/s 3:31<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 6.9it/s 25.9s0.2s\n",
      "                   all       5752      15252       0.91      0.867      0.917      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    203/300      8.04G     0.7193     0.5186      1.436          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:26<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.3s0.1s\n",
      "                   all       5752      15252       0.91      0.868      0.917      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    204/300      8.07G      0.719     0.5194      1.439          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:26<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.4s0.1s\n",
      "                   all       5752      15252       0.91      0.868      0.917      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    205/300      7.99G     0.7235     0.5232      1.444          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.3s0.1s\n",
      "                   all       5752      15252      0.909      0.869      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    206/300      8.06G     0.7183     0.5199      1.435         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.3s0.1s\n",
      "                   all       5752      15252       0.91      0.868      0.917       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    207/300      8.42G     0.7159     0.5167      1.433         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:26<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.4s0.1s\n",
      "                   all       5752      15252       0.91      0.868      0.917       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    208/300      8.06G     0.7208     0.5218      1.437         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1ss\n",
      "                   all       5752      15252       0.91      0.868      0.917      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    209/300      8.02G     0.7188     0.5211       1.44          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.4s0.1s\n",
      "                   all       5752      15252       0.91      0.868      0.917      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    210/300      8.04G     0.7177     0.5194      1.436         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:26<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.2s0.1s\n",
      "                   all       5752      15252      0.912      0.867      0.917      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    211/300      8.03G     0.7208     0.5183      1.439         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:26<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.4s0.1s\n",
      "                   all       5752      15252      0.911      0.867      0.917      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    212/300      8.08G     0.7178     0.5195      1.435         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.4s0.1s\n",
      "                   all       5752      15252      0.911      0.867      0.917      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    213/300      8.28G     0.7141     0.5131       1.43         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.3s0.1s\n",
      "                   all       5752      15252      0.912      0.866      0.917      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    214/300      8.05G     0.7165     0.5165      1.433          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:26<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.4s0.1s\n",
      "                   all       5752      15252      0.912      0.866      0.917       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    215/300      8.01G     0.7123     0.5123      1.434          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:26<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.3s0.1s\n",
      "                   all       5752      15252      0.912      0.866      0.917       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    216/300      8.05G     0.7129     0.5128      1.436          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:26<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.3s0.1s\n",
      "                   all       5752      15252      0.912      0.867      0.917       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    217/300      8.03G     0.7074     0.5091      1.425          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:26<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.3s0.1s\n",
      "                   all       5752      15252      0.911      0.867      0.917       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    218/300      8.04G     0.7083     0.5118      1.428         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.4s0.1s\n",
      "                   all       5752      15252      0.912      0.866      0.917       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    219/300      8.03G      0.705     0.5052      1.426         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.3s0.1s\n",
      "                   all       5752      15252      0.914      0.865      0.917       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    220/300      8.07G     0.7081     0.5114      1.431          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.3s0.1s\n",
      "                   all       5752      15252      0.913      0.865      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    221/300      8.02G     0.7083     0.5087      1.426          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.1it/s 22.3s0.1s\n",
      "                   all       5752      15252      0.913      0.866      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    222/300      8.08G     0.7124      0.511      1.428          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:28<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1ss\n",
      "                   all       5752      15252      0.913      0.865      0.916      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    223/300      8.04G     0.7039     0.5038      1.419         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.0it/s 3:28<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.6s0.1ss\n",
      "                   all       5752      15252      0.912      0.867      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    224/300      8.05G     0.7074     0.5119      1.431          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:28<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1ss\n",
      "                   all       5752      15252      0.911      0.867      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    225/300      7.99G     0.7029      0.505      1.423         24        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1s\n",
      "                   all       5752      15252       0.91      0.868      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    226/300      8.06G      0.705     0.5056      1.425         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1s\n",
      "                   all       5752      15252      0.909      0.868      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    227/300      8.02G      0.709     0.5088      1.425         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:28<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1ss\n",
      "                   all       5752      15252      0.907      0.869      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    228/300      8.05G     0.7009     0.5043      1.419          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1ss\n",
      "                   all       5752      15252      0.907       0.87      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    229/300      8.01G     0.7025     0.5045      1.419         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.0it/s 3:29<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 7.9it/s 22.7s0.1ss\n",
      "                   all       5752      15252      0.907       0.87      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    230/300      8.06G     0.7002     0.4994      1.414          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.0it/s 3:28<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 7.9it/s 22.7s0.1ss\n",
      "                   all       5752      15252      0.908      0.868      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    231/300      8.02G      0.701     0.5059       1.42         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.4s0.1ss\n",
      "                   all       5752      15252      0.909      0.868      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    232/300      8.09G     0.6982      0.498      1.414         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:28<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1s\n",
      "                   all       5752      15252      0.909      0.868      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    233/300      8.01G     0.7001     0.5033      1.418          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1s\n",
      "                   all       5752      15252      0.909      0.868      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    234/300      8.05G     0.6996     0.4987      1.416         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1s\n",
      "                   all       5752      15252      0.908      0.869      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    235/300      8.04G     0.6964     0.5006      1.415         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.0it/s 3:30<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 7.8it/s 23.0s0.1ss\n",
      "                   all       5752      15252      0.908       0.87      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    236/300      8.08G     0.6972      0.499      1.415          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.0it/s 3:29<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 7.9it/s 22.8s0.1ss\n",
      "                   all       5752      15252      0.907       0.87      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    237/300      8.02G     0.6997     0.5029      1.417         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1ss\n",
      "                   all       5752      15252      0.907      0.871      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    238/300      8.03G     0.6956        0.5      1.417         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1s\n",
      "                   all       5752      15252      0.907      0.871      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    239/300      8.04G     0.6922     0.4969       1.41          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1ss\n",
      "                   all       5752      15252      0.907      0.871      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    240/300      8.08G     0.6957     0.4997      1.414          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:28<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1ss\n",
      "                   all       5752      15252       0.91      0.869      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    241/300      8.02G     0.6964     0.4992      1.414         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:28<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.6s0.1ss\n",
      "                   all       5752      15252       0.91      0.868      0.916      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    242/300      8.05G     0.6944     0.4984      1.414         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.6s0.1ss\n",
      "                   all       5752      15252       0.91      0.869      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    243/300      8.06G     0.6921     0.4959       1.41         26        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:28<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.6s0.1s\n",
      "                   all       5752      15252       0.91      0.869      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    244/300      8.09G     0.6883     0.4935      1.407         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:28<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1ss\n",
      "                   all       5752      15252      0.908      0.871      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    245/300      8.02G     0.6886     0.4939      1.404          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.6s0.1ss\n",
      "                   all       5752      15252      0.911      0.867      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    246/300      8.09G     0.6908     0.4923        1.4          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:28<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.5s0.1ss\n",
      "                   all       5752      15252      0.911      0.867      0.916      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    247/300      8.03G     0.6874     0.4898      1.403        100        640: 86% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ 1083/1259 6.1it/s 2:59<28.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K    260/300      8.05G     0.6806     0.4837      1.396         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1259/1259 6.1it/s 3:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 8.0it/s 22.6s0.1s\n",
      "                   all       5752      15252      0.907       0.87      0.915       0.62\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 50 epochs. Best results observed at epoch 210, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "59 epochs completed in 3.781 hours.\n",
      "Optimizer stripped from /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/weights/last.pt, 40.5MB\n",
      "Optimizer stripped from /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/weights/best.pt, 40.5MB\n",
      "\n",
      "Validating /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/weights/best.pt...\n",
      "Ultralytics 8.3.197 üöÄ Python-3.9.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 15840MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 7.6it/s 23.6s0.1ss\n",
      "                   all       5752      15252      0.909      0.867      0.917      0.621\n",
      "Speed: 0.1ms preprocess, 2.1ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1m/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640\u001b[0m\n",
      "\n",
      "--- Stage 1 Training Complete ---\n",
      "Final Stage 1 best.pt exists: True\n"
     ]
    }
   ],
   "source": [
    "# === Stage 1: Robust training cell with epoch check ===\n",
    "\n",
    "stage1_project = STAGE1_ROOT\n",
    "stage1_exp_name = STAGE1_NAME\n",
    "\n",
    "stage1_exp_dir = STAGE1_ROOT / STAGE1_NAME\n",
    "stage1_best = stage1_exp_dir / \"weights\" / \"best.pt\"\n",
    "stage1_last = stage1_exp_dir / \"weights\" / \"last.pt\"\n",
    "stage1_results_csv = stage1_exp_dir / \"results.csv\"\n",
    "\n",
    "print(\"Stage 1 experiment dir:\", stage1_exp_dir)\n",
    "print(\"Existing Stage 1 best.pt:\", stage1_best.is_file())\n",
    "print(\"Existing Stage 1 last.pt:\", stage1_last.is_file())\n",
    "print(\"Existing Stage 1 results.csv:\", stage1_results_csv.is_file())\n",
    "\n",
    "# How many epochs are already recorded?\n",
    "epochs_done_s1 = 0\n",
    "if stage1_results_csv.is_file():\n",
    "    with stage1_results_csv.open(\"r\") as f:\n",
    "        lines = [ln for ln in f.readlines() if ln.strip()]\n",
    "    if len(lines) > 1:\n",
    "        epochs_done_s1 = len(lines) - 1\n",
    "\n",
    "print(f\"Stage 1 epochs recorded in results.csv: {epochs_done_s1} / {EPOCHS_STAGE1}\")\n",
    "\n",
    "stage1_train_args = dict(\n",
    "    data=str(DATA_YAML),\n",
    "    epochs=EPOCHS_STAGE1,\n",
    "    imgsz=IMG_SIZE_STAGE1,\n",
    "    batch=BATCH_SIZE_STAGE1,\n",
    "    device=DEVICE,\n",
    "    project=str(stage1_project),\n",
    "    name=stage1_exp_name,\n",
    "    optimizer=BEST_OPTIMIZER,\n",
    "    lr0=BEST_LR0,\n",
    "    lrf=LRS_STAGE1_FINAL_MULT,\n",
    "    momentum=MOMENTUM_STAGE1,\n",
    "    weight_decay=WEIGHT_DECAY_STAGE1,\n",
    "    box=BEST_BOX_WEIGHT,\n",
    "    cls=BEST_CLS_WEIGHT,\n",
    "    kobj=BEST_OBJ_WEIGHT,\n",
    "    dfl=DFL_STAGE1,\n",
    "    dropout=BEST_DROPOUT,\n",
    "    cos_lr=True,\n",
    "    patience=PATIENCE_STAGE1,\n",
    "    amp=True,\n",
    "    cache=\"disk\",\n",
    "    warmup_epochs=WARMUP_EPOCHS,\n",
    "    warmup_momentum=WARMUP_MOMENTUM,\n",
    "    mosaic=BEST_MOSAIC,\n",
    "    mixup=BEST_MIXUP,\n",
    "    flipud=BEST_FLIPUD,\n",
    "    fliplr=BEST_FLIPLR,\n",
    "    hsv_h=BEST_HSV_H,\n",
    "    hsv_s=BEST_HSV_S,\n",
    "    hsv_v=BEST_HSV_V,\n",
    "    copy_paste=0.0,\n",
    "    scale=0.5,\n",
    "    shear=2.0,\n",
    "    max_det=1000,\n",
    "    plots=True,\n",
    "    save_period=25,\n",
    "    verbose=True,\n",
    "    seed=SEED,\n",
    "    exist_ok=True,\n",
    ")\n",
    "\n",
    "if stage1_best.is_file() and epochs_done_s1 >= EPOCHS_STAGE1:\n",
    "    print(\"\\n--- Stage 1 appears complete (best.pt present and epochs_done >= target). Skipping training. ---\")\n",
    "else:\n",
    "    if stage1_last.is_file():\n",
    "        print(\"\\n--- Resuming Stage 1 from last.pt with true YOLO resume ---\")\n",
    "        model_s1 = YOLO(str(stage1_last))\n",
    "        # True internal resume: use original training args from the run\n",
    "        results_s1 = model_s1.train(resume=True)\n",
    "    else:\n",
    "        print(\"\\n--- Starting Stage 1 from base YOLO11 weights ---\")\n",
    "        model_s1 = YOLO(YOLO11_WEIGHTS)\n",
    "        stage1_train_args[\"resume\"] = False\n",
    "        results_s1 = model_s1.train(**stage1_train_args)\n",
    "\n",
    "    print(\"\\n--- Stage 1 Training Complete ---\")\n",
    "\n",
    "# Refresh paths after training/skip\n",
    "stage1_exp_dir = STAGE1_ROOT / STAGE1_NAME\n",
    "stage1_best = stage1_exp_dir / \"weights\" / \"best.pt\"\n",
    "stage1_last = stage1_exp_dir / \"weights\" / \"last.pt\"\n",
    "print(\"Final Stage 1 best.pt exists:\", stage1_best.is_file())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb505871",
   "metadata": {},
   "source": [
    "## 7. Stage 1 ‚Äì Locate best checkpoint\n",
    "\n",
    "Double-check that `best.pt` exists in the expected location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3295cb0c-d543-462d-9902-292a9d28ec48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Stage 1 best.pt exists: True\n"
     ]
    }
   ],
   "source": [
    "# Refresh paths after training/skip\n",
    "stage1_exp_dir = STAGE1_ROOT / STAGE1_NAME\n",
    "stage1_best = stage1_exp_dir / \"weights\" / \"best.pt\"\n",
    "stage1_last = stage1_exp_dir / \"weights\" / \"last.pt\"\n",
    "print(\"Final Stage 1 best.pt exists:\", stage1_best.is_file())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fbf41b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 experiment dir: /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640\n",
      "Stage 1 best weights  : /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/weights/best.pt\n",
      "Stage 1 last weights  : /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/weights/last.pt\n"
     ]
    }
   ],
   "source": [
    "print(\"Stage 1 experiment dir:\", stage1_exp_dir)\n",
    "print(\"Stage 1 best weights  :\", stage1_best)\n",
    "print(\"Stage 1 last weights  :\", stage1_last)\n",
    "\n",
    "assert stage1_best.is_file(), \"Stage 1 best.pt not found - training may not have completed successfully.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03df106",
   "metadata": {},
   "source": [
    "## 8. Stage 1 ‚Äì Evaluation on val and test\n",
    "\n",
    "We evaluate Stage 1 `best.pt` on:\n",
    "\n",
    "- **Validation split** (`split=\"val\"`)\n",
    "- **Test split** (`split=\"test\"`)\n",
    "\n",
    "Then we:\n",
    "\n",
    "- Save metrics to JSON and CSV.\n",
    "- Analyze the **best 2** and **worst 2** detections on the **test split** based on IoU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa90e024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.197 üöÄ Python-3.9.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 15837MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 6.6¬±7.2 MB/s, size: 81.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/labels/val.cache... 5752 images, 455 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5752/5752 14.8Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/val/fishclef_05829.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/val/fishclef_05830.jpg: 2 duplicate labels removed\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 360/360 12.7it/s 28.3s<0.1s\n",
      "                   all       5752      15252       0.91      0.867      0.918      0.624\n",
      "Speed: 0.1ms preprocess, 3.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/eval/val_eval_stage1\u001b[0m\n",
      "Stage 1 validation metrics saved to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/eval/metrics_val.json\n",
      "Ultralytics 8.3.197 üöÄ Python-3.9.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 15837MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2012.1¬±889.0 MB/s, size: 28.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/labels/test.cache... 2883 images, 228 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2883/2883 9.0Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/test/fishclef_06542.jpg: 1 duplicate labels removed\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 181/181 12.5it/s 14.5s0.1s\n",
      "                   all       2883       7567      0.912      0.866      0.917      0.615\n",
      "Speed: 0.1ms preprocess, 3.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/eval/test_eval_stage1\u001b[0m\n",
      "Stage 1 test metrics saved to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/eval/metrics_test.json\n",
      "Metrics CSV saved to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/eval/metrics_summary_stage1.csv\n",
      "\n",
      "--- Stage 1: Best and Worst Detections on Test Split ---\n",
      "The results object does not contain per-image results.\n"
     ]
    }
   ],
   "source": [
    "stage1_eval_dir = stage1_exp_dir / \"eval\"\n",
    "stage1_eval_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Validation evaluation\n",
    "s1_val_json = stage1_eval_dir / \"metrics_val.json\"\n",
    "metrics_s1_val, s1_val_results_obj = evaluate_and_save(\n",
    "    weights_path=stage1_best,\n",
    "    data_yaml=DATA_YAML,\n",
    "    split=\"val\",\n",
    "    imgsz=IMG_SIZE_STAGE1,\n",
    "    project=stage1_eval_dir,\n",
    "    name=\"val_eval_stage1\",\n",
    "    seed=SEED,\n",
    "    out_json=s1_val_json,\n",
    ")\n",
    "print(\"Stage 1 validation metrics saved to\", s1_val_json)\n",
    "\n",
    "# Test evaluation\n",
    "s1_test_json = stage1_eval_dir / \"metrics_test.json\"\n",
    "metrics_s1_test, s1_test_results_obj = evaluate_and_save(\n",
    "    weights_path=stage1_best,\n",
    "    data_yaml=DATA_YAML,\n",
    "    split=\"test\",\n",
    "    imgsz=IMG_SIZE_STAGE1,\n",
    "    project=stage1_eval_dir,\n",
    "    name=\"test_eval_stage1\",\n",
    "    seed=SEED,\n",
    "    out_json=s1_test_json,\n",
    ")\n",
    "print(\"Stage 1 test metrics saved to\", s1_test_json)\n",
    "\n",
    "# Save CSV summary\n",
    "s1_csv_path = stage1_eval_dir / \"metrics_summary_stage1.csv\"\n",
    "export_metrics_csv(metrics_s1_val, metrics_s1_test, s1_csv_path)\n",
    "\n",
    "print(\"\\n--- Stage 1: Best and Worst Detections on Test Split ---\")\n",
    "analyze_best_worst_detections(s1_test_results_obj, split=\"test\", top_k=2, min_iou=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ce766-264a-4d77-afb7-ed5479f3a50a",
   "metadata": {},
   "source": [
    "## 9.2. Stage 3 ‚Äì Fine-tuning from Stage 1 best at 1024x1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836305a0-4831-4812-a1fb-4e0ad63d107f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 3 dir   : /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024\n",
      "Stage 3 best  : /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024/weights/best.pt\n",
      "Stage 3 last  : /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024/weights/last.pt\n",
      "Stage 3 CSV   : /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024/results.csv\n",
      "Stage 3 epochs in CSV (last): 0 / 150\n",
      "\n",
      "--- No usable epoch*.pt <= CSV epoch; falling back to Stage 3 best or Stage 1 best ---\n",
      "Stage 3 best.pt not found; starting from Stage 1 best.pt\n",
      "\n",
      "Starting Stage 3 from logical epoch 0, continuing to 150.\n",
      "No previous Stage 3 CSV; starting fresh.\n",
      "Training 150 epochs (logical 1..150).\n",
      "New https://pypi.org/project/ultralytics/8.3.231 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.197 üöÄ Python-3.9.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 15837MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=5.0, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.4, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=2.0, dnn=False, dropout=0.1, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.07835, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0083, hsv_s=0.02738, hsv_v=0.33474, imgsz=1024, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00164, lrf=0.1, mask_ratio=4, max_det=1000, mixup=0.4553, mode=train, model=/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/weights/best.pt, momentum=0.9, mosaic=0.9129, multi_scale=False, name=yolo11_ht_vision_fish_stage3_1024, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=42, shear=2.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 23        [16, 19, 22]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLO11m summary: 231 layers, 20,053,779 parameters, 20,053,763 gradients, 68.2 GFLOPs\n",
      "\n",
      "Transferred 649/649 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1587.8¬±1266.9 MB/s, size: 49.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/labels/train.cache... 20130 images, 1590 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 20130/20130 44.5Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/train/fishclef_00030.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/train/fishclef_04732.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/train/fishclef_05932.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/train/fishclef_07144.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/train/fishclef_10671.jpg: 1 duplicate labels removed\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (40.5GB Disk): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 20130/20130 95.3Kit/s 0.2s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1018.8¬±772.3 MB/s, size: 123.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/labels/val.cache... 5752 images, 455 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5752/5752 8.1Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/val/fishclef_05829.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/val/fishclef_05830.jpg: 2 duplicate labels removed\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (11.6GB Disk): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5752/5752 85.9Kit/s 0.1s\n",
      "Plotting labels to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00164, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024\u001b[0m\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/150      9.99G     0.7725     0.5945       1.62         61       1024: 1% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 16/2517 4.8it/s 7.5s<8:40"
     ]
    }
   ],
   "source": [
    "# ===== STAGE 3 TRAINING =====\n",
    "\n",
    "EPOCHS_STAGE3 = 150\n",
    "STAGE3_NAME = f\"{EXPERIMENT_BASE_NAME}_stage3_1024\"\n",
    "\n",
    "stage3_project = STAGE3_ROOT\n",
    "stage3_exp_name = STAGE3_NAME\n",
    "stage3_exp_dir = stage3_project / stage3_exp_name\n",
    "stage3_weights_dir = stage3_exp_dir / \"weights\"\n",
    "\n",
    "stage3_best = stage3_weights_dir / \"best.pt\"\n",
    "stage3_last = stage3_weights_dir / \"last.pt\"\n",
    "stage3_results_csv = stage3_exp_dir / \"results.csv\"\n",
    "\n",
    "# Stage 1 best (fallback start for Stage 3)\n",
    "STAGE1_NAME = f\"{EXPERIMENT_BASE_NAME}_stage1_640\"\n",
    "stage1_exp_dir = STAGE1_ROOT / STAGE1_NAME\n",
    "stage1_best = stage1_exp_dir / \"weights\" / \"best.pt\"\n",
    "\n",
    "print(f\"Stage 3 dir   : {stage3_exp_dir}\")\n",
    "print(f\"Stage 3 best  : {stage3_best}\")\n",
    "print(f\"Stage 3 last  : {stage3_last}\")\n",
    "print(f\"Stage 3 CSV   : {stage3_results_csv}\")\n",
    "\n",
    "def get_last_epoch_from_csv(csv_path: Path) -> int:\n",
    "    if not csv_path.is_file():\n",
    "        return 0\n",
    "    last_epoch = 0\n",
    "    with csv_path.open(\"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader, None)  # header\n",
    "        for row in reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            try:\n",
    "                e = int(row[0])\n",
    "                if e > last_epoch:\n",
    "                    last_epoch = e\n",
    "            except Exception:\n",
    "                continue\n",
    "    return last_epoch\n",
    "\n",
    "epochs_done_s3 = get_last_epoch_from_csv(stage3_results_csv)\n",
    "print(f\"Stage 3 epochs in CSV (last): {epochs_done_s3} / {EPOCHS_STAGE3}\")\n",
    "\n",
    "stage3_train_args = dict(\n",
    "    data=str(DATA_YAML),\n",
    "    epochs=EPOCHS_STAGE3,\n",
    "    imgsz=IMG_SIZE_STAGE3,\n",
    "    batch=8,\n",
    "    device=DEVICE,\n",
    "    project=str(stage3_project),\n",
    "    name=stage3_exp_name,\n",
    "    resume=False,\n",
    "    optimizer=\"SGD\",\n",
    "    lr0=0.00164,\n",
    "    lrf=0.1,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005,\n",
    "    box=5.0,\n",
    "    cls=0.4,\n",
    "    kobj=1.0,\n",
    "    dfl=2.0,\n",
    "    dropout=0.1,\n",
    "    cos_lr=True,\n",
    "    patience=50,\n",
    "    amp=True,\n",
    "    cache=\"disk\",\n",
    "    warmup_epochs=3,\n",
    "    warmup_momentum=0.8,\n",
    "    mosaic=0.9129,\n",
    "    mixup=0.4553,\n",
    "    flipud=0.07835,\n",
    "    fliplr=0.5,\n",
    "    hsv_h=0.0083,\n",
    "    hsv_s=0.02738,\n",
    "    hsv_v=0.33474,\n",
    "    copy_paste=0.0,\n",
    "    scale=0.5,\n",
    "    shear=2.0,\n",
    "    max_det=1000,\n",
    "    plots=True,\n",
    "    save_period=5,      # <<< save every 5 epochs\n",
    "    verbose=True,\n",
    "    seed=SEED,\n",
    "    exist_ok=True,\n",
    ")\n",
    "\n",
    "# If already complete, skip\n",
    "if stage3_best.is_file() and epochs_done_s3 >= EPOCHS_STAGE3:\n",
    "    print(\"\\n--- Stage 3 appears complete (best.pt present and epochs_done >= target). Skipping. ---\")\n",
    "else:\n",
    "    model_s3 = None\n",
    "    resume_flag = False\n",
    "    start_epoch = 0\n",
    "\n",
    "    # 1) Try to resume from last.pt\n",
    "    if stage3_last.is_file():\n",
    "        print(\"\\n--- Trying to resume Stage 3 from last.pt ---\")\n",
    "        try:\n",
    "            model_s3 = YOLO(str(stage3_last))\n",
    "            resume_flag = True\n",
    "            print(\"Loaded Stage 3 last.pt; will resume.\")\n",
    "        except Exception as e:\n",
    "            print(f\"WARNING: Stage 3 last.pt corrupted ({e}). Deleting and falling back.\")\n",
    "            try:\n",
    "                stage3_last.unlink()\n",
    "                print(\"Deleted corrupted last.pt.\")\n",
    "            except Exception as del_e:\n",
    "                print(f\"WARNING: Could not delete last.pt: {del_e}\")\n",
    "            model_s3 = None\n",
    "            resume_flag = False\n",
    "\n",
    "    # 2) If last.pt unusable, use latest epoch*.pt <= epochs_done_s3\n",
    "    if model_s3 is None:\n",
    "        epoch_ckpts = []\n",
    "        if stage3_weights_dir.is_dir():\n",
    "            for p in stage3_weights_dir.glob(\"epoch*.pt\"):\n",
    "                # expects names like epoch5.pt, epoch10.pt, ...\n",
    "                stem = p.stem  # 'epoch5'\n",
    "                try:\n",
    "                    ep = int(stem.replace(\"epoch\", \"\"))\n",
    "                    epoch_ckpts.append((ep, p))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "        valid = [(ep, p) for ep, p in epoch_ckpts if ep <= epochs_done_s3]\n",
    "        if valid:\n",
    "            valid.sort(key=lambda x: x[0], reverse=True)\n",
    "            start_epoch, ckpt = valid[0]\n",
    "            print(f\"\\n--- Resuming Stage 3 from {ckpt.name} (epoch {start_epoch}) ---\")\n",
    "            model_s3 = YOLO(str(ckpt))\n",
    "            resume_flag = False\n",
    "        else:\n",
    "            # 3) Fallback: Stage 3 best, else Stage 1 best\n",
    "            print(\"\\n--- No usable epoch*.pt <= CSV epoch; falling back to Stage 3 best or Stage 1 best ---\")\n",
    "            if stage3_best.is_file():\n",
    "                print(\"Starting Stage 3 from its own best.pt\")\n",
    "                model_s3 = YOLO(str(stage3_best))\n",
    "            else:\n",
    "                print(\"Stage 3 best.pt not found; starting from Stage 1 best.pt\")\n",
    "                assert stage1_best.is_file(), \"Stage 1 best.pt not found - cannot start Stage 3.\"\n",
    "                model_s3 = YOLO(str(stage1_best))\n",
    "            start_epoch = min(epochs_done_s3, EPOCHS_STAGE3)\n",
    "            resume_flag = False\n",
    "\n",
    "    if model_s3 is None:\n",
    "        raise RuntimeError(\"No valid model for Stage 3 could be created.\")\n",
    "\n",
    "    # === TRAINING ===\n",
    "    if resume_flag:\n",
    "        print(f\"\\nResuming Stage 3 with resume=True up to epoch {EPOCHS_STAGE3}.\")\n",
    "        stage3_train_args[\"resume\"] = True\n",
    "        stage3_train_args[\"epochs\"] = EPOCHS_STAGE3\n",
    "        results_s3 = model_s3.train(**stage3_train_args)\n",
    "        print(\"\\n--- Stage 3 training complete (resumed from last.pt) ---\")\n",
    "    else:\n",
    "        print(f\"\\nStarting Stage 3 from logical epoch {start_epoch}, continuing to {EPOCHS_STAGE3}.\")\n",
    "        # 1) Preserve CSV rows up to start_epoch\n",
    "        old_header, old_rows = None, []\n",
    "        if stage3_results_csv.is_file():\n",
    "            with stage3_results_csv.open(\"r\") as f:\n",
    "                reader = csv.reader(f)\n",
    "                old_header = next(reader, None)\n",
    "                for row in reader:\n",
    "                    if not row:\n",
    "                        continue\n",
    "                    try:\n",
    "                        e = int(row[0])\n",
    "                        if e <= start_epoch:\n",
    "                            old_rows.append(row)\n",
    "                    except Exception:\n",
    "                        continue\n",
    "            print(f\"Kept {len(old_rows)} CSV rows with epoch <= {start_epoch}.\")\n",
    "        else:\n",
    "            print(\"No previous Stage 3 CSV; starting fresh.\")\n",
    "\n",
    "        epochs_remaining = max(EPOCHS_STAGE3 - start_epoch, 0)\n",
    "        if epochs_remaining <= 0:\n",
    "            print(f\"No epochs remaining (start_epoch={start_epoch}, target={EPOCHS_STAGE3}). Skipping training.\")\n",
    "        else:\n",
    "            print(f\"Training {epochs_remaining} epochs (logical {start_epoch+1}..{EPOCHS_STAGE3}).\")\n",
    "            stage3_train_args[\"resume\"] = False\n",
    "            stage3_train_args[\"epochs\"] = epochs_remaining\n",
    "\n",
    "            results_s3 = model_s3.train(**stage3_train_args)\n",
    "            print(\"\\n--- Stage 3 training complete (from checkpoint or Stage1 best) ---\")\n",
    "\n",
    "            # 2) Merge new CSV with shifted epochs\n",
    "            if stage3_results_csv.is_file():\n",
    "                with stage3_results_csv.open(\"r\") as f:\n",
    "                    reader = csv.reader(f)\n",
    "                    new_header = next(reader, None)\n",
    "                    new_rows = [r for r in reader if r]\n",
    "\n",
    "                header = old_header or new_header\n",
    "                shifted_new_rows = []\n",
    "                for row in new_rows:\n",
    "                    try:\n",
    "                        e = int(row[0])\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                    row[0] = str(start_epoch + e)\n",
    "                    shifted_new_rows.append(row)\n",
    "\n",
    "                with stage3_results_csv.open(\"w\", newline=\"\") as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    if header:\n",
    "                        writer.writerow(header)\n",
    "                    writer.writerows(old_rows)\n",
    "                    writer.writerows(shifted_new_rows)\n",
    "\n",
    "                print(f\"Stage 3 CSV updated with continuous epoch count up to {EPOCHS_STAGE3}.\")\n",
    "            else:\n",
    "                print(\"WARNING: Stage 3 CSV missing after training; cannot merge epochs.\")\n",
    "\n",
    "# Refresh and report\n",
    "stage3_best = stage3_weights_dir / \"best.pt\"\n",
    "stage3_last = stage3_weights_dir / \"last.pt\"\n",
    "print(\"Final Stage 3 best.pt exists:\", stage3_best.is_file())\n",
    "print(\"Final Stage 3 last.pt exists:\", stage3_last.is_file())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae2b40b",
   "metadata": {},
   "source": [
    "## 10. Stage 3 ‚Äì Locate best checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dc1c22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 3 experiment dir: /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024\n",
      "Stage 3 best weights  : /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024/weights/best.pt\n",
      "Stage 3 last weights  : /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024/weights/last.pt\n"
     ]
    }
   ],
   "source": [
    "print(\"Stage 3 experiment dir:\", stage3_exp_dir)\n",
    "print(\"Stage 3 best weights  :\", stage3_best)\n",
    "print(\"Stage 3 last weights  :\", stage3_last)\n",
    "\n",
    "assert stage3_best.is_file(), \"Stage 3 best.pt not found - fine-tuning may not have completed successfully.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bc5a0e",
   "metadata": {},
   "source": [
    "## 11. Stage 3 ‚Äì Evaluation on val and test\n",
    "\n",
    "Repeat the evaluation pipeline for Stage 3:\n",
    "\n",
    "- Evaluate on **val** and **test**.\n",
    "- Save metrics (JSON + CSV).\n",
    "- Print **best 3** and **worst 3** detections on test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26af8797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.197 üöÄ Python-3.9.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 15837MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 7.7¬±12.1 MB/s, size: 42.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/labels/val.cache... 5752 images, 455 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5752/5752 14.8Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/val/fishclef_05829.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/val/fishclef_05830.jpg: 2 duplicate labels removed\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 360/360 5.6it/s 1:04<0.2ss\n",
      "                   all       5752      15252      0.907      0.866      0.913      0.621\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024/eval/val_eval_stage3\u001b[0m\n",
      "Stage 3 validation metrics saved to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024/eval/metrics_val.json\n",
      "Ultralytics 8.3.197 üöÄ Python-3.9.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 15837MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1784.4¬±497.7 MB/s, size: 26.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/labels/test.cache... 2883 images, 228 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2883/2883 7.1Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Dataset/images/test/fishclef_06542.jpg: 1 duplicate labels removed\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 181/181 5.6it/s 32.4s0.2ss\n",
      "                   all       2883       7567      0.911      0.858      0.912      0.612\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024/eval/test_eval_stage3\u001b[0m\n",
      "Stage 3 test metrics saved to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024/eval/metrics_test.json\n",
      "Metrics CSV saved to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024/eval/metrics_summary_stage3.csv\n",
      "\n",
      "--- Stage 3: Best and Worst Detections on Test Split ---\n",
      "The results object does not contain per-image results.\n"
     ]
    }
   ],
   "source": [
    "stage3_eval_dir = stage3_exp_dir / \"eval\"\n",
    "stage3_eval_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Validation evaluation\n",
    "s3_val_json = stage3_eval_dir / \"metrics_val.json\"\n",
    "metrics_s3_val, s3_val_results_obj = evaluate_and_save(\n",
    "    weights_path=stage3_best,\n",
    "    data_yaml=DATA_YAML,\n",
    "    split=\"val\",\n",
    "    imgsz=IMG_SIZE_STAGE3,\n",
    "    project=stage3_eval_dir,\n",
    "    name=\"val_eval_stage3\",\n",
    "    seed=SEED,\n",
    "    out_json=s3_val_json,\n",
    ")\n",
    "print(\"Stage 3 validation metrics saved to\", s3_val_json)\n",
    "\n",
    "# Test evaluation\n",
    "s3_test_json = stage3_eval_dir / \"metrics_test.json\"\n",
    "metrics_s3_test, s3_test_results_obj = evaluate_and_save(\n",
    "    weights_path=stage3_best,\n",
    "    data_yaml=DATA_YAML,\n",
    "    split=\"test\",\n",
    "    imgsz=IMG_SIZE_STAGE3,\n",
    "    project=stage3_eval_dir,\n",
    "    name=\"test_eval_stage3\",\n",
    "    seed=SEED,\n",
    "    out_json=s3_test_json,\n",
    ")\n",
    "print(\"Stage 3 test metrics saved to\", s3_test_json)\n",
    "\n",
    "# Save CSV summary\n",
    "s3_csv_path = stage3_eval_dir / \"metrics_summary_stage3.csv\"\n",
    "export_metrics_csv(metrics_s3_val, metrics_s3_test, s3_csv_path)\n",
    "\n",
    "print(\"\\n--- Stage 3: Best and Worst Detections on Test Split ---\")\n",
    "analyze_best_worst_detections(s3_test_results_obj, split=\"test\", top_k=2, min_iou=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a17d15",
   "metadata": {},
   "source": [
    "## 12. Compare Stage 1 vs Stage 3 metrics\n",
    "\n",
    "Here we build a quick comparison table from the **test** metrics of Stage 1 and Stage 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24b0e40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>Stage1_test</th>\n",
       "      <th>Stage3_test</th>\n",
       "      <th>Delta_Stage3_minus_Stage1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fitness</td>\n",
       "      <td>0.645356</td>\n",
       "      <td>0.642022</td>\n",
       "      <td>-0.003334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metrics/mAP50(B)</td>\n",
       "      <td>0.917138</td>\n",
       "      <td>0.912384</td>\n",
       "      <td>-0.004754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>metrics/mAP50-95(B)</td>\n",
       "      <td>0.615158</td>\n",
       "      <td>0.611982</td>\n",
       "      <td>-0.003176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>metrics/precision(B)</td>\n",
       "      <td>0.911953</td>\n",
       "      <td>0.910660</td>\n",
       "      <td>-0.001293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>metrics/recall(B)</td>\n",
       "      <td>0.866394</td>\n",
       "      <td>0.858068</td>\n",
       "      <td>-0.008326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 metric  Stage1_test  Stage3_test  Delta_Stage3_minus_Stage1\n",
       "0               fitness     0.645356     0.642022                  -0.003334\n",
       "1      metrics/mAP50(B)     0.917138     0.912384                  -0.004754\n",
       "2   metrics/mAP50-95(B)     0.615158     0.611982                  -0.003176\n",
       "3  metrics/precision(B)     0.911953     0.910660                  -0.001293\n",
       "4     metrics/recall(B)     0.866394     0.858068                  -0.008326"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 vs Stage 3 test metrics comparison saved to: /mnt/Data1/mpiccolo/HT_Vision/Training_Results/stage1_vs_stage3_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_keys = sorted(set(metrics_s1_test.keys()) | set(metrics_s3_test.keys()))\n",
    "rows = []\n",
    "for k in all_keys:\n",
    "    s1_val = metrics_s1_test.get(k, None)\n",
    "    s3_val = metrics_s3_test.get(k, None)\n",
    "    rows.append({\n",
    "        \"metric\": k,\n",
    "        \"Stage1_test\": s1_val,\n",
    "        \"Stage3_test\": s3_val,\n",
    "    })\n",
    "\n",
    "df_compare = pd.DataFrame(rows)\n",
    "\n",
    "# Delta column (Stage3 - Stage1)\n",
    "df_compare[\"Delta_Stage3_minus_Stage1\"] = (\n",
    "    df_compare[\"Stage3_test\"] - df_compare[\"Stage1_test\"]\n",
    ")\n",
    "\n",
    "display(df_compare)\n",
    "\n",
    "comparison_csv = TRAINING_ROOT / \"stage1_vs_stage3_test_metrics.csv\"\n",
    "df_compare.to_csv(comparison_csv, index=False)\n",
    "print(\"Stage 1 vs Stage 3 test metrics comparison saved to:\", comparison_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34917b5",
   "metadata": {},
   "source": [
    "## 13. Inference Demo ‚Äì Stage 1 and Stage 3\n",
    "\n",
    "We now run inference for both Stage 1 and Stage 3 **best models** on the custom image:\n",
    "\n",
    "```text\n",
    "/mnt/Data1/mpiccolo/HT_Vision/inference_pinksalmon.png\n",
    "```\n",
    "\n",
    "Results (annotated images) are saved under the respective stage folders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dac2c9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference with /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/yolo11_ht_vision_fish_stage1_640/weights/best.pt on /mnt/Data1/mpiccolo/HT_Vision/inference_pinksalmon.png ...\n",
      "\n",
      "image 1/1 /mnt/Data1/mpiccolo/HT_Vision/inference_pinksalmon.png: 352x640 33 fishs, 29.4ms\n",
      "Speed: 1.1ms preprocess, 29.4ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Results saved to \u001b[1m/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage1/inference_yolo11_ht_vision_fish_stage1_640\u001b[0m\n",
      "Inference complete. Check the output folder above.\n",
      "\n",
      "Running inference with /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/yolo11_ht_vision_fish_stage3_1024/weights/best.pt on /mnt/Data1/mpiccolo/HT_Vision/inference_pinksalmon.png ...\n",
      "\n",
      "image 1/1 /mnt/Data1/mpiccolo/HT_Vision/inference_pinksalmon.png: 544x1024 34 fishs, 30.8ms\n",
      "Speed: 2.3ms preprocess, 30.8ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 1024)\n",
      "Results saved to \u001b[1m/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Stage3/inference_yolo11_ht_vision_fish_stage3_1024\u001b[0m\n",
      "Inference complete. Check the output folder above.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_inference(weights_path: Path, img_path: str, imgsz: int, project: Path, name: str):\n",
    "    if not os.path.isfile(img_path):\n",
    "        print(f\"Inference image not found: {img_path}\")\n",
    "        return\n",
    "    model_inf = YOLO(str(weights_path))\n",
    "    print(f\"Running inference with {weights_path} on {img_path} ...\")\n",
    "    _ = model_inf.predict(\n",
    "        source=img_path,\n",
    "        imgsz=imgsz,\n",
    "        conf=0.25,\n",
    "        max_det=100,\n",
    "        device=DEVICE,\n",
    "        project=str(project),\n",
    "        name=name,\n",
    "        save=True,\n",
    "    )\n",
    "    print(\"Inference complete. Check the output folder above.\\n\")\n",
    "\n",
    "# Stage 1 inference\n",
    "run_inference(\n",
    "    weights_path=stage1_best,\n",
    "    img_path=INFERENCE_IMAGE,\n",
    "    imgsz=IMG_SIZE_STAGE1,\n",
    "    project=STAGE1_ROOT,\n",
    "    name=f\"inference_{STAGE1_NAME}\",\n",
    ")\n",
    "\n",
    "# Stage 3 inference\n",
    "run_inference(\n",
    "    weights_path=stage3_best,\n",
    "    img_path=INFERENCE_IMAGE,\n",
    "    imgsz=IMG_SIZE_STAGE3,\n",
    "    project=STAGE3_ROOT,\n",
    "    name=f\"inference_{STAGE3_NAME}\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba84b748",
   "metadata": {},
   "source": [
    "### 14. Evaluation on Unseen Datasets\n",
    "\n",
    "This section is prepared for evaluating Stage 1 and Stage 3 on an **unseen dataset**.\n",
    "\n",
    "Once you have the unseen dataset ready, create a `data.yaml` for it and set its path in the next cell, e.g.:\n",
    "\n",
    "```python\n",
    "UNSEEN_DATA_YAML = Path(\"/path/to/unseen/data.yaml\")\n",
    "```\n",
    "\n",
    "Then you can run evaluations for both stages on that unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5795529",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNSEEN_DATASETS = {\n",
    "    \"Fish_Video_Object_Tracking_Kaggle\": Path(\n",
    "        \"/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Unseen_ds/Fish_Video_Object_Tracking_Kaggle/data.yaml\"\n",
    "    ),\n",
    "    \"Kaggle_Fish_Dataset\": Path(\n",
    "        \"/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Unseen_ds/Kaggle_Fish_Dataset/data.yaml\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c339f0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fish_Video_Object_Tracking_Kaggle] Running unseen evaluation on /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Unseen_ds/Fish_Video_Object_Tracking_Kaggle/data.yaml\n",
      "Ultralytics 8.3.197 üöÄ Python-3.9.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 15837MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 39.6¬±5.8 MB/s, size: 499.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Unseen_ds/Fish_Video_Object_Tracking_Kaggle/labels... 99 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 206.4it/s 0.5s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Unseen_ds/Fish_Video_Object_Tracking_Kaggle/labels.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7/7 4.4it/s 1.6s0.2s\n",
      "                   all         99        979      0.827      0.715      0.806      0.557\n",
      "Speed: 0.3ms preprocess, 5.5ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "Results saved to \u001b[1m/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Unseen/Fish_Video_Object_Tracking_Kaggle/Stage1/Fish_Video_Object_Tracking_Kaggle_unseen_stage1\u001b[0m\n",
      "[Fish_Video_Object_Tracking_Kaggle] Stage 1 unseen metrics saved to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Unseen/Fish_Video_Object_Tracking_Kaggle/Stage1/metrics_unseen_stage1.json\n",
      "Ultralytics 8.3.197 üöÄ Python-3.9.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 15837MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 5148.7¬±863.9 MB/s, size: 497.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Unseen_ds/Fish_Video_Object_Tracking_Kaggle/labels.cache... 99 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 315.8Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7/7 3.8it/s 1.8s0.2s\n",
      "                   all         99        979      0.821      0.697      0.806      0.582\n",
      "Speed: 0.8ms preprocess, 7.0ms inference, 0.0ms loss, 6.4ms postprocess per image\n",
      "Results saved to \u001b[1m/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Unseen/Fish_Video_Object_Tracking_Kaggle/Stage3/Fish_Video_Object_Tracking_Kaggle_unseen_stage3\u001b[0m\n",
      "[Fish_Video_Object_Tracking_Kaggle] Stage 3 unseen metrics saved to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Unseen/Fish_Video_Object_Tracking_Kaggle/Stage3/metrics_unseen_stage3.json\n",
      "Metrics CSV saved to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Unseen/Fish_Video_Object_Tracking_Kaggle/stage1_vs_stage3_unseen_metrics.csv\n",
      "[Fish_Video_Object_Tracking_Kaggle] Stage1 vs Stage3 unseen metrics CSV: /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Unseen/Fish_Video_Object_Tracking_Kaggle/stage1_vs_stage3_unseen_metrics.csv\n",
      "[Kaggle_Fish_Dataset] Running unseen evaluation on /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Unseen_ds/Kaggle_Fish_Dataset/data.yaml\n",
      "Ultralytics 8.3.197 üöÄ Python-3.9.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 15837MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1488.6¬±3263.9 MB/s, size: 343.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Unseen_ds/Kaggle_Fish_Dataset/labels... 629 images, 1 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 629/629 501.7it/s 1.3s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Unseen_ds/Kaggle_Fish_Dataset/images/0654.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Unseen_ds/Kaggle_Fish_Dataset/labels.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 40/40 7.6it/s 5.3s<0.2s\n",
      "                   all        629      18873      0.804      0.318      0.492      0.255\n",
      "Speed: 0.1ms preprocess, 3.4ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1m/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Unseen/Kaggle_Fish_Dataset/Stage1/Kaggle_Fish_Dataset_unseen_stage1\u001b[0m\n",
      "[Kaggle_Fish_Dataset] Stage 1 unseen metrics saved to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Unseen/Kaggle_Fish_Dataset/Stage1/metrics_unseen_stage1.json\n",
      "Ultralytics 8.3.197 üöÄ Python-3.9.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 15837MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 4985.0¬±1692.4 MB/s, size: 563.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Unseen_ds/Kaggle_Fish_Dataset/labels.cache... 629 images, 1 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 629/629 1.4Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/Data1/mpiccolo/HT_Vision/HT_Vision_Unseen_ds/Kaggle_Fish_Dataset/images/0654.jpg: 1 duplicate labels removed\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 40/40 4.5it/s 8.9s0.2s\n",
      "                   all        629      18873      0.763      0.338      0.471      0.238\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1m/mnt/Data1/mpiccolo/HT_Vision/Training_Results/Unseen/Kaggle_Fish_Dataset/Stage3/Kaggle_Fish_Dataset_unseen_stage3\u001b[0m\n",
      "[Kaggle_Fish_Dataset] Stage 3 unseen metrics saved to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Unseen/Kaggle_Fish_Dataset/Stage3/metrics_unseen_stage3.json\n",
      "Metrics CSV saved to /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Unseen/Kaggle_Fish_Dataset/stage1_vs_stage3_unseen_metrics.csv\n",
      "[Kaggle_Fish_Dataset] Stage1 vs Stage3 unseen metrics CSV: /mnt/Data1/mpiccolo/HT_Vision/Training_Results/Unseen/Kaggle_Fish_Dataset/stage1_vs_stage3_unseen_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "unseen_root = TRAINING_ROOT / \"Unseen\"\n",
    "unseen_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for ds_name, yaml_path in UNSEEN_DATASETS.items():\n",
    "    if not yaml_path.is_file():\n",
    "        print(f\"[{ds_name}] data.yaml not found, skipping:\", yaml_path)\n",
    "        continue\n",
    "\n",
    "    print(f\"[{ds_name}] Running unseen evaluation on\", yaml_path)\n",
    "\n",
    "    ds_root = unseen_root / ds_name\n",
    "    ds_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ---------- Stage 1 on unseen ----------\n",
    "    s1_unseen_dir = ds_root / \"Stage1\"\n",
    "    s1_unseen_json = s1_unseen_dir / \"metrics_unseen_stage1.json\"\n",
    "    metrics_s1_unseen, _ = evaluate_and_save(\n",
    "        weights_path=stage1_best,\n",
    "        data_yaml=yaml_path,\n",
    "        split=\"test\",\n",
    "        imgsz=IMG_SIZE_STAGE1,\n",
    "        project=s1_unseen_dir,\n",
    "        name=f\"{ds_name}_unseen_stage1\",\n",
    "        seed=SEED,\n",
    "        out_json=s1_unseen_json,\n",
    "    )\n",
    "    print(f\"[{ds_name}] Stage 1 unseen metrics saved to\", s1_unseen_json)\n",
    "\n",
    "    # ---------- Stage 3 on unseen ----------\n",
    "    s3_unseen_dir = ds_root / \"Stage3\"\n",
    "    s3_unseen_json = s3_unseen_dir / \"metrics_unseen_stage3.json\"\n",
    "    metrics_s3_unseen, _ = evaluate_and_save(\n",
    "        weights_path=stage3_best,        \n",
    "        data_yaml=yaml_path,\n",
    "        split=\"test\",                     \n",
    "        imgsz=IMG_SIZE_STAGE3,          \n",
    "        project=s3_unseen_dir,\n",
    "        name=f\"{ds_name}_unseen_stage3\",\n",
    "        seed=SEED,\n",
    "        out_json=s3_unseen_json,\n",
    "    )\n",
    "    print(f\"[{ds_name}] Stage 3 unseen metrics saved to\", s3_unseen_json)\n",
    "\n",
    "    # ---------- CSV comparison: Stage 1 vs Stage 3 ----------\n",
    "    unseen_csv = ds_root / \"stage1_vs_stage3_unseen_metrics.csv\"\n",
    "    export_metrics_csv(metrics_s1_unseen, metrics_s3_unseen, unseen_csv)\n",
    "    print(f\"[{ds_name}] Stage1 vs Stage3 unseen metrics CSV:\", unseen_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10feed04-6a90-4f61-be1a-0ca802fc573d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
